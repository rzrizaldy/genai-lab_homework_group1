{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part A: Experimenting with Prompt Design\n",
    "\n",
    "**Experiments can be conducted using either:**\n",
    "1. **Automated:** HuggingFace Inference API (run code cells below)\n",
    "2. **Manual:** https://gpt-oss.com/ (copy prompts, paste responses)\n",
    "\n",
    "For automated method, set `HF_TOKEN` in `.env` file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup (for automated inference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing connection...\n",
      "Response: Hello!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize client with HuggingFace router\n",
    "client = OpenAI(\n",
    "    base_url=\"https://router.huggingface.co/v1\",\n",
    "    api_key=os.environ.get(\"HF_TOKEN\", \"your_token_here\"),\n",
    ")\n",
    "\n",
    "def get_completion(prompt, model=\"openai/gpt-oss-20b:groq\"):\n",
    "    \"\"\"Get completion from HuggingFace inference API\"\"\"\n",
    "    try:\n",
    "        completion = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        )\n",
    "        return completion.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "# Test connection\n",
    "print(\"Testing connection...\")\n",
    "test = get_completion(\"Say 'Hello!'\")\n",
    "print(f\"Response: {test}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Task 1: [Your Task Name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt 1.1: [Style/Approach]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "what model are you?\n",
      "\n",
      "\n",
      "Response:\n",
      "I’m built on OpenAI’s GPT‑4 architecture (the GPT‑4‑turbo model).\n"
     ]
    }
   ],
   "source": [
    "prompt_1_1 = \"\"\"\n",
    "what model are you?\n",
    "\"\"\"\n",
    "print(prompt_1_1)\n",
    "\n",
    "# Option 1: Run automated\n",
    "response_1_1 = get_completion(prompt_1_1)\n",
    "print(f\"\\nResponse:\\n{response_1_1}\")\n",
    "\n",
    "# Option 2: Paste manual response\n",
    "# response_1_1 = \"\"\"\n",
    "# [Paste response from gpt-oss.com]\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt 1.2: [Style/Approach]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_1_2 = \"\"\"\n",
    "[Your prompt here]\n",
    "\"\"\"\n",
    "print(prompt_1_2)\n",
    "\n",
    "# response_1_2 = get_completion(prompt_1_2)\n",
    "# print(f\"\\nResponse:\\n{response_1_2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt 1.3: [Style/Approach]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_1_3 = \"\"\"\n",
    "[Your prompt here]\n",
    "\"\"\"\n",
    "print(prompt_1_3)\n",
    "\n",
    "# response_1_3 = get_completion(prompt_1_3)\n",
    "# print(f\"\\nResponse:\\n{response_1_3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt 1.4: [Style/Approach]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_1_4 = \"\"\"\n",
    "[Your prompt here]\n",
    "\"\"\"\n",
    "print(prompt_1_4)\n",
    "\n",
    "# response_1_4 = get_completion(prompt_1_4)\n",
    "# print(f\"\\nResponse:\\n{response_1_4}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt 1.5: [Style/Approach]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_1_5 = \"\"\"\n",
    "[Your prompt here]\n",
    "\"\"\"\n",
    "print(prompt_1_5)\n",
    "\n",
    "# response_1_5 = get_completion(prompt_1_5)\n",
    "# print(f\"\\nResponse:\\n{response_1_5}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Task 2: [Your Task Name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt 2.1: [Style/Approach]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_2_1 = \"\"\"\n",
    "[Your prompt here]\n",
    "\"\"\"\n",
    "print(prompt_2_1)\n",
    "\n",
    "# response_2_1 = get_completion(prompt_2_1)\n",
    "# print(f\"\\nResponse:\\n{response_2_1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt 2.2: [Style/Approach]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_2_2 = \"\"\"\n",
    "[Your prompt here]\n",
    "\"\"\"\n",
    "print(prompt_2_2)\n",
    "\n",
    "# response_2_2 = get_completion(prompt_2_2)\n",
    "# print(f\"\\nResponse:\\n{response_2_2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt 2.3: [Style/Approach]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_2_3 = \"\"\"\n",
    "[Your prompt here]\n",
    "\"\"\"\n",
    "print(prompt_2_3)\n",
    "\n",
    "# response_2_3 = get_completion(prompt_2_3)\n",
    "# print(f\"\\nResponse:\\n{response_2_3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt 2.4: [Style/Approach]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_2_4 = \"\"\"\n",
    "[Your prompt here]\n",
    "\"\"\"\n",
    "print(prompt_2_4)\n",
    "\n",
    "# response_2_4 = get_completion(prompt_2_4)\n",
    "# print(f\"\\nResponse:\\n{response_2_4}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt 2.5: [Style/Approach]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_2_5 = \"\"\"\n",
    "[Your prompt here]\n",
    "\"\"\"\n",
    "print(prompt_2_5)\n",
    "\n",
    "# response_2_5 = get_completion(prompt_2_5)\n",
    "# print(f\"\\nResponse:\\n{response_2_5}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Task 3: [Your Task Name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt 3.1: [Style/Approach]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_3_1 = \"\"\"\n",
    "[Your prompt here]\n",
    "\"\"\"\n",
    "print(prompt_3_1)\n",
    "\n",
    "# response_3_1 = get_completion(prompt_3_1)\n",
    "# print(f\"\\nResponse:\\n{response_3_1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt 3.2: [Style/Approach]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_3_2 = \"\"\"\n",
    "[Your prompt here]\n",
    "\"\"\"\n",
    "print(prompt_3_2)\n",
    "\n",
    "# response_3_2 = get_completion(prompt_3_2)\n",
    "# print(f\"\\nResponse:\\n{response_3_2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt 3.3: [Style/Approach]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_3_3 = \"\"\"\n",
    "[Your prompt here]\n",
    "\"\"\"\n",
    "print(prompt_3_3)\n",
    "\n",
    "# response_3_3 = get_completion(prompt_3_3)\n",
    "# print(f\"\\nResponse:\\n{response_3_3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt 3.4: [Style/Approach]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_3_4 = \"\"\"\n",
    "[Your prompt here]\n",
    "\"\"\"\n",
    "print(prompt_3_4)\n",
    "\n",
    "# response_3_4 = get_completion(prompt_3_4)\n",
    "# print(f\"\\nResponse:\\n{response_3_4}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt 3.5: [Style/Approach]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_3_5 = \"\"\"\n",
    "[Your prompt here]\n",
    "\"\"\"\n",
    "print(prompt_3_5)\n",
    "\n",
    "# response_3_5 = get_completion(prompt_3_5)\n",
    "# print(f\"\\nResponse:\\n{response_3_5}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
